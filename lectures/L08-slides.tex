\input{configuration}

\title{Lecture 8 --- Cache Coherency }

\author{Jeff Zarnett \\ \small \texttt{jzarnett@uwaterloo.ca}}
\institute{Department of Electrical and Computer Engineering \\
  University of Waterloo}
\date{\today}


\begin{document}

\begin{frame}
  \titlepage

 \end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Introduction}

  \begin{center}
    \includegraphics[scale=0.7]{images/coherency}

    Image courtesy of Wikipedia.
  \end{center}

Each CPU has its own cache: coordination is needed!
  
  {\bf Coherency:}
  \begin{itemize}
    \item Values in all caches are consistent;
    \item System behaves as if all CPUs are using shared memory.
  \end{itemize}
  
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Cache Coherence Example}

  
  Initially in main memory: {\tt x = 7}.

  \begin{enumerate}
    \item {\tt CPU1} reads x, puts the value in its cache.
    \item {\tt CPU3} reads x, puts the value in its cache.
    \item {\tt CPU3} modifies {\tt x := 42}
    \item {\tt CPU1} reads x \ldots ~from its cache?
    \item {\tt CPU2} reads x. Which value does it get?
  \end{enumerate}
  ~\\

  Unless we do something, {\tt CPU1} is going to read invalid data.
  
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\begin{frame}
\frametitle{Planes and Trains}
\begin{center}
\includegraphics[width=0.5\textwidth]{images/aircanada.jpg}
\includegraphics[width=0.5\textwidth]{images/deutschebahn.png}
\end{center}
\end{frame}



\begin{frame}
\frametitle{Snoopy Caches}

The simplest way to ``do something''
is to use Snoopy caches. 

No, not this kind of Snoopy (sadly):

\begin{center}
	\includegraphics[width=0.4\textwidth]{images/peanuts-snoopy1.jpg}
\end{center}



\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{High-Level Explanation of Snoopy Caches}

  Snoopy: the caches are spying on each other.
  
  \begin{itemize}
    \item Each CPU is connected to a simple bus.
    \item Each CPU ``snoops'' to observe if a memory location is read or written
      by another CPU.
    \item We need a cache controller for every CPU.
  \end{itemize}
  ~\\
  {\bf What happens?}

  \begin{itemize}
    \item Each CPU reads the bus to see if any memory operation is relevant. If
      it is, the controller takes appropriate action.
  \end{itemize}
  
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{A Distributed Approach}


This is a distributed approach; no centralized state is maintained. 

Each cache with a copy of data from a block of physical memory knows whether it is shared or not. 

Whenever a CPU issues a memory write, the other CPUs are watching (snooping around) to observe if that memory location is in their cache. 

If it is, then the CPU will need to take action.

\end{frame}


\begin{frame}
\frametitle{We Need Some Action!}

What does action mean?

The Air Canada action was \alert{update}.

The Deutsche Bahn action was \alert{invalidate}.

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Write-Through Cache}

  
Simplest type of cache coherence:
  \begin{itemize}
    \item All cache writes are done to main memory.
    \item All cache writes also appear on the bus.
    \item If another CPU snoops and sees it has the same location in
      its cache, it will either {\it invalidate} or {\it update} the
      data.
\end{itemize}
~\\

    For write-through caches: normally, when you write to an invalidated
    location, you bypass the cache and go directly to memory (aka {\bf
      write no-allocate}).

  
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{frame}
\frametitle{The Daaaaaaaaaleks!}

Our chosen approach:

\begin{center}
\includegraphics[width=0.6\textwidth]{images/dalek-invalidate.jpg}
\end{center}

\end{frame}



\begin{frame}
\frametitle{In-val-i-daaaaaate!}

Invalidation is the most common protocol. 

It means the data in the cache of other CPUs is not updated, it's just noted as being out of date (invalid).  

\end{frame}


\begin{frame}
\frametitle{In-val-i-daaaaaate!}
If we want to do a read and there's a miss, we can poke around in other caches to see who has the most recent cached version. 

This is a bit like going into a room and yelling ``Does anybody have block...?'', in some sort of multicast version of the card game ``Go Fish''. 


Regardless, the most recent value appears in memory, always.


\end{frame}



\begin{frame}
\frametitle{Let's Yell}

There are also write broadcast protocols, in which case all versions in all caches get updated when there is a write to a shared block. 

But it uses lots of bandwidth and is not necessarily a good idea. 

\begin{center}
	\includegraphics[width=0.4\textwidth]{images/multicast.jpg}
\end{center}

\end{frame}



\begin{frame}
\frametitle{Let's Yell}

It does, however prevent the costly cache miss that follows an invalidate. 

Sadly, as we are mere users and not hardware architects, we don't get to decide; we just have to live with whichever one is on the hardware we get. Bummer.


\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Write-Through Protocol}

  
  \begin{itemize}
    \item Two states, {\bf valid} and {\bf invalid}, for each memory location.
    \item Events are either from a processor ({\bf Pr}) or the {\bf Bus}.
  \end{itemize}
  \vfill
  \begin{center}
    \begin{tabular}{llll}
      {\bf State} & {\bf Observed} & {\bf Generated} & {\bf Next State}\\
      Valid   & PrRd  &       & Valid\\
      Valid   & PrWr  & BusWr & Valid\\
      Valid   & BusWr &       & Invalid\\
      Invalid & PrWr  & BusWr & Valid\\
      Invalid & PrRd  & BusRd & Valid\\
    \end{tabular}
  \end{center}
  
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Write-Through Protocol Example}

  

  \begin{itemize}
    \item For simplicity (this isn't an architecture course), assume all cache
      reads/writes are atomic.
  \end{itemize}
  \vfill
  {\bf Using the same example as before:}

  Initially in main memory: {\tt x = 7}.

  \begin{enumerate}
    \item {\tt CPU1} reads x, puts the value in its cache. \structure{(valid)}
    \item {\tt CPU3} reads x, puts the value in its cache. \structure{(valid)}
    \item {\tt CPU3} modifies {\tt x := 42}. \structure{(write to memory)}
      \begin{itemize}
        \item \structure{{\tt CPU1} snoops and marks data as invalid.}
      \end{itemize}
    \item {\tt CPU1} reads x, \structure{from main memory. (valid)}
    \item {\tt CPU2} reads x, \structure{from main memory. (valid)}
  \end{enumerate}
  
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Write-Back Cache}


  \begin{itemize}
    \item What if, in our example, {\tt CPU3} writes to {\tt x} 3 times?\\[1em]
    \item Main goal: delay the write to memory as long as possible.\\[1em]
    \item At minimum, we have to add a ``dirty'' bit:\\
     \quad Indicates our data has not yet been written to memory.
  \end{itemize}
  

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Write-Back Implementation}

  
     The simplest type of write-back protocol (MSI), with 3 states:
      \begin{itemize}
        \item {\bf Modified}---only this cache has a valid copy; \\
          \quad main memory is {\bf out-of-date}.
        \item {\bf Shared}---location is unmodified, \\
          \quad up-to-date with main
          memory; \\
          \quad may be present in other caches (also up-to-date).
        \item {\bf Invalid}---same as before.
      \end{itemize}~\\
      
     Initial state, upon first read, is ``shared''.\\[1em]

     Implementation will only write the data to memory if another
        processor requests it.\\[1em]

     During write-back, a processor may read the data from the bus.
  
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{MSI Protocol}

  
  \begin{itemize}
    \item Bus write-back (or flush) is {\bf BusWB}.
    \item Exclusive read on the bus is {\bf BusRdX}.
  \end{itemize}~\\

  \begin{center}
    \begin{tabular}{llll}
      {\bf State} & {\bf Observed} & {\bf Generated} & {\bf Next State}\\
      Modified   & PrRd   &        & Modified\\
      Modified   & PrWr   &        & Modified\\
      Modified   & BusRd  & BusWB  & Shared\\
      Modified   & BusRdX & BusWB  & Invalid\\
      Shared     & PrRd   &        & Shared\\
      Shared     & BusRd  &        & Shared\\
      Shared     & BusRdX &        & Invalid\\
      Shared     & PrWr   & BusRdX & Modified\\
      Invalid    & PrRd   & BusRd  & Shared\\
      Invalid    & PrWr   & BusRdX & Modified\\
    \end{tabular}
  \end{center}
  
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{MSI Example}

  

  {\bf Using the same example as before:}

  Initially in main memory: {\tt x = 7}.

  \begin{enumerate}
    \item {\tt CPU1} reads x from memory. \structure{(BusRd, shared)}
    \item {\tt CPU3} reads x from memory. \structure{(BusRd, shared)}
    \item {\tt CPU3} modifies {\tt x := 42}
      \begin{itemize}
        \item \structure{Generates a BusRdX.}
        \item \structure{{\tt CPU1} snoops and invalidates x.}
        \item \structure{{\tt CPU3} changes {\tt x}'s state to modified.}
      \end{itemize}
    \item {\tt CPU1} reads x:
      \begin{itemize}
        \item \structure{Generates a BusRd.}
        \item \structure{{\tt CPU3} writes back the data and sets x to shared.}
        \item \structure{{\tt CPU1} reads the new value from the bus as shared.}
      \end{itemize}
    \item {\tt CPU2} reads x from memory. \structure{(BusRd, shared)}
  \end{enumerate}
  
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{An Extension to MSI: MESI}

  
    The most common protocol for cache coherence is MESI.\\[1em]
    Adds another state:
      \begin{itemize}
        \item {\bf Modified}---only this cache has a valid copy; \\
\qquad main memory is {\bf out-of-date}.
        \item {\bf Exclusive}---only this cache has a valid copy; \\
\qquad main memory is {\bf up-to-date}.
        \item {\bf Shared}---same as before.
        \item {\bf Invalid}---same as before.
      \end{itemize}
~\\

    MESI allows a processor to modify data exclusive to it, \\without
      having to communicate with the bus.\\
    MESI is \structure{safe}: in E state, no other processor has the
      data.
  
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Even More States!}

  
    MESIF (used in latest i7 processors):
      \begin{itemize}
        \item {\bf Forward}---basically a shared state; but, current
          cache is the only one that will respond to a request to
          transfer the data.
      \end{itemize}~\\[1em]

    Hence: a processor requesting data that is already shared or exclusive will
      only get one response transferring the data.\\[1em]
    Permits more efficient usage of the bus.
  
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\begin{frame}
\frametitle{False Sharing}

\begin{center}
	\includegraphics[width=0.7\textwidth]{images/joey-friends.jpg}
\end{center}

False sharing: program has two unrelated data elements that are mapped to the same cache line/location.

\end{frame}


\begin{frame}[fragile]
\frametitle{False Sharing}



\begin{lstlisting}[language=C]
char a[10];
char b[10];
\end{lstlisting}

They don't overlap but are located next to each other in memory.

\end{frame}


\begin{frame}
\frametitle{False Sharing}

Solution: Heap allocation? Maybe... 

Make both arrays bigger, wasting some space...?

\end{frame}


\begin{frame}
\frametitle{False Sharing}

\begin{center}
\includegraphics[width=0.6\textwidth]{images/falsesharing.png}
\end{center}

Is wasting a little space worth it? Yes!

(Plus, putting arrays in a struct
and padding enables future updates to the struct.)
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Cache Coherency Summary}
  
We saw the basics of cache coherence (more of an architecture
      thing).
      
Knowing this stuff allows us to make wise decisions (e.g., false sharing)!      
      
There are other protocols for cache coherence, each with their own
      trade-offs.


  
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}

